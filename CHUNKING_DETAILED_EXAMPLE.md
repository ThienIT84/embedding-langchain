# ğŸ”ª Giáº£i ThÃ­ch Chi Tiáº¿t: CÃ¡ch Chia Chunk Má»™t Trang

## Má»¥c TiÃªu
File **chunker.py** láº¥y má»™t trang PDF dÃ i (vÃ­ dá»¥ 5000 kÃ½ tá»±) vÃ  chia thÃ nh nhiá»u **chunk nhá»** (má»—i chunk ~900 kÃ½ tá»± theo config).

---

## ğŸ“Š VÃ­ Dá»¥ Cá»¥ Thá»ƒ

### 1. INPUT: Má»™t trang tá»« text_extractor.py

Giáº£ sá»­ `text_extractor.py` Ä‘Ã£ Ä‘á»c **Trang 5** cá»§a PDF, extract Ä‘Æ°á»£c text nhÆ° sau:

```
Trang 5:
"LangChain lÃ  má»™t framework giÃºp xÃ¢y dá»±ng á»©ng dá»¥ng AI. 
NÃ³ cung cáº¥p cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ lÃ m viá»‡c vá»›i LLM (Large Language Models).

RecursiveCharacterTextSplitter lÃ  má»™t cÃ´ng cá»¥ cá»§a LangChain dÃ¹ng Ä‘á»ƒ chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n nhá».

CÃ¡ch hoáº¡t Ä‘á»™ng:
1. Äáº§u tiÃªn, nÃ³ cá»‘ gáº¯ng chia theo '\n\n' (2 dÃ²ng trá»‘ng)
2. Náº¿u Ä‘oáº¡n váº«n quÃ¡ dÃ i, chia theo '\n' (1 dÃ²ng)
3. Náº¿u váº«n quÃ¡ dÃ i, chia theo ' ' (khoáº£ng tráº¯ng)
4. Náº¿u cÃ²n quÃ¡ dÃ i, chia tá»«ng kÃ½ tá»±

Overlap (chá»“ng láº¥p) = 200 kÃ½ tá»±: má»—i chunk má»›i sáº½ cÃ³ 200 kÃ½ tá»± cuá»‘i cá»§a chunk trÆ°á»›c."
```

**Thá»‘ng kÃª:**
- Trang: 5
- Äá»™ dÃ i: ~650 kÃ½ tá»±
- LÃ : 1 `DocumentChunk` tá»« `text_extractor.py`

---

### 2. CONFIG: CÃ i Ä‘áº·t chia chunk

Tá»« `.env`:
```
CHUNK_SIZE=900
CHUNK_OVERLAP=200
```

Trong `chunker.py`:
```python
_splitter = RecursiveCharacterTextSplitter(
    chunk_size=900,           # Má»—i chunk tá»‘i Ä‘a 900 kÃ½ tá»±
    chunk_overlap=200,        # Overlap 200 kÃ½ tá»± giá»¯a cÃ¡c chunk
    separators=["\n\n", "\n", " ", ""]  # Thá»© tá»± Æ°u tiÃªn chia
)
```

---

### 3. PROCESS: QuÃ¡ trÃ¬nh chia chunk

#### Step 1: Gá»i hÃ m `split_chunks()`

```python
# Text trang 5 (650 kÃ½ tá»±)
page_5_chunk = DocumentChunk(
    text="LangChain lÃ  má»™t framework...",
    page_number=5
)

# Gá»i hÃ m
result = split_chunks([page_5_chunk])  # Pass iterable cÃ³ 1 pháº§n tá»­
```

#### Step 2: VÃ²ng láº·p ngoÃ i - `for source_idx, chunk in enumerate(chunks)`

```python
for source_idx, chunk in enumerate(chunks):  # source_idx = 0
    # chunk = DocumentChunk(text="LangChain lÃ ...", page_number=5)
    
    pieces = _splitter.split_text(chunk.text)
    # Gá»i RecursiveCharacterTextSplitter.split_text()
```

**RecursiveCharacterTextSplitter lÃ m gÃ¬?**

Input: 
```
"LangChain lÃ  má»™t framework...[650 kÃ½ tá»±]...chia tá»«ng kÃ½ tá»±"
```

Output: VÃ¬ 650 < 900, nÃªn **khÃ´ng cáº§n chia**:
```python
pieces = [
    "LangChain lÃ  má»™t framework giÃºp xÃ¢y dá»±ng á»©ng dá»¥ng AI. NÃ³ cung cáº¥p cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ lÃ m viá»‡c vá»›i LLM (Large Language Models).\n\nRecursiveCharacterTextSplitter lÃ  má»™t cÃ´ng cá»¥ cá»§a LangChain dÃ¹ng Ä‘á»ƒ chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n nhá».\n\nCÃ¡ch hoáº¡t Ä‘á»™ng:\n1. Äáº§u tiÃªn, nÃ³ cá»‘ gáº¯ng chia theo '\n\n' (2 dÃ²ng trá»‘ng)\n2. Náº¿u Ä‘oáº¡n váº«n quÃ¡ dÃ i, chia theo '\n' (1 dÃ²ng)\n3. Náº¿u váº«n quÃ¡ dÃ i, chia theo ' ' (khoáº£ng tráº¯ng)\n4. Náº¿u cÃ²n quÃ¡ dÃ i, chia tá»«ng kÃ½ tá»±\n\nOverlap (chá»“ng láº¥p) = 200 kÃ½ tá»±: má»—i chunk má»›i sáº½ cÃ³ 200 kÃ½ tá»± cuá»‘i cá»§a chunk trÆ°á»›c."
]
# pieces cÃ³ 1 pháº§n tá»­ (vÃ¬ text < 900 kÃ½ tá»±)
```

#### Step 3: VÃ²ng láº·p trong - `for piece_idx, piece in enumerate(pieces)`

```python
for piece_idx, piece in enumerate(pieces):  # piece_idx = 0
    text = piece.strip()  # XÃ³a khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i
    
    if not text:  # Náº¿u text rá»—ng thÃ¬ bá» qua
        continue
    
    # Náº¿u text khÃ´ng rá»—ng, thÃªm vÃ o output
    output.append(
        TextChunk(
            text=text,
            page_number=chunk.page_number,  # = 5
            chunk_index=len(output) + 1,    # = 0 + 1 = 1
        )
    )
```

#### Step 4: OUTPUT

```python
output = [
    TextChunk(
        text="LangChain lÃ  má»™t framework...",
        page_number=5,
        chunk_index=1  # ÄÃ¢y lÃ  chunk thá»© 1 trong toÃ n bá»™ output
    )
]

return output
```

---

## ğŸ”´ VÃ­ Dá»¥ 2: Trang DÃ i Cáº§n Chia Nhiá»u Láº§n

### INPUT: Trang 10 cÃ³ 3000 kÃ½ tá»±

```
Trang 10:
"LangChain cung cáº¥p nhiá»u thÃ nh pháº§n... [3000 kÃ½ tá»±]... á»©ng dá»¥ng AI hiá»‡u quáº£"
```

### PROCESS:

**RecursiveCharacterTextSplitter.split_text()** sáº½:
1. Chia theo `"\n\n"` (paragraph)
2. Náº¿u paragraphs váº«n > 900, chia tiáº¿p theo `"\n"` (dÃ²ng)
3. Náº¿u váº«n quÃ¡ dÃ i, chia theo `" "` (tá»«)
4. Náº¿u cÃ²n quÃ¡ dÃ i, chia tá»«ng kÃ½ tá»±

**Result:**
```python
pieces = [
    "LangChain cung cáº¥p nhiá»u thÃ nh pháº§n...[900 kÃ½ tá»±]...",           # Chunk 1
    "[200 overlap kÃ½ tá»± tá»« chunk 1]...LangChain há»— trá»£...[900 kÃ½ tá»±]",  # Chunk 2
    "[200 overlap kÃ½ tá»± tá»« chunk 2]...á»©ng dá»¥ng AI hiá»‡u quáº£"           # Chunk 3
]
# pieces cÃ³ 3 pháº§n tá»­
```

### LOOP:

```python
# Iteration 1: piece_idx = 0
output.append(TextChunk(
    text="LangChain cung cáº¥p...",
    page_number=10,
    chunk_index=1  # len(output=0) + 1
))

# Iteration 2: piece_idx = 1
output.append(TextChunk(
    text="[200 overlap]...LangChain há»— trá»£...",
    page_number=10,
    chunk_index=2  # len(output=1) + 1
))

# Iteration 3: piece_idx = 2
output.append(TextChunk(
    text="[200 overlap]...á»©ng dá»¥ng AI hiá»‡u quáº£",
    page_number=10,
    chunk_index=3  # len(output=2) + 1
))
```

### OUTPUT:

```python
[
    TextChunk(text="...", page_number=10, chunk_index=1),
    TextChunk(text="...", page_number=10, chunk_index=2),
    TextChunk(text="...", page_number=10, chunk_index=3),
]
```

---

## ğŸ§® Hiá»ƒu RÃµ CÃ¡c Biáº¿n

### `chunk_index = len(output) + 1`

**Táº¡i sao dÃ¹ng `len(output) + 1`?**

```python
output = []

# ThÃªm chunk 1
output.append(TextChunk(..., chunk_index=len(output) + 1))  # len=0, chunk_index=1

# ThÃªm chunk 2
output.append(TextChunk(..., chunk_index=len(output) + 1))  # len=1, chunk_index=2

# ThÃªm chunk 3
output.append(TextChunk(..., chunk_index=len(output) + 1))  # len=2, chunk_index=3
```

**Result:**
```python
output = [
    TextChunk(..., chunk_index=1),  # position 0, chunk_index 1
    TextChunk(..., chunk_index=2),  # position 1, chunk_index 2
    TextChunk(..., chunk_index=3),  # position 2, chunk_index 3
]
```

**Ã nghÄ©a:**
- `chunk_index` = sá»‘ thá»© tá»± chunk (báº¯t Ä‘áº§u tá»« 1, khÃ´ng pháº£i 0)
- LÃ  **global index** (tÃ­nh trÃªn toÃ n bá»™ document, khÃ´ng riÃªng tá»«ng trang)

---

### `piece.strip()`

```python
piece = "   LangChain lÃ  framework   \n"
text = piece.strip()  # XÃ³a khoáº£ng tráº¯ng + \n Ä‘áº§u/cuá»‘i
# text = "LangChain lÃ  framework"
```

**CÃ¡c hÃ m .strip() tÆ°Æ¡ng tá»±:**
- `.strip()` - xÃ³a Ä‘áº§u + cuá»‘i
- `.lstrip()` - xÃ³a Ä‘áº§u
- `.rstrip()` - xÃ³a cuá»‘i

---

### `if not text: continue`

```python
if not text:  # Náº¿u text rá»—ng
    continue  # Bá» qua, khÃ´ng add vÃ o output

# VÃ­ dá»¥:
piece = "   \n   "
text = piece.strip()  # ""
if not text:  # True
    continue  # Bá» qua pháº§n tá»­ nÃ y
```

---

## ğŸ“ˆ SÆ¡ Äá»“ QuÃ¡ TrÃ¬nh

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Iterable[DocumentChunk] (tá»« text_extractor.py)          â”‚
â”‚ Trang 5: 650 kÃ½ tá»±                                              â”‚
â”‚ Trang 10: 3000 kÃ½ tá»±                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  for chunk in... â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
    Trang 5           RecursiveCharacterTextSplitter    Trang 10
    650 kÃ½ tá»±         (split_text)                     3000 kÃ½ tá»±
        â”‚                     â”‚                         â”‚
        â–¼                     â–¼                         â–¼
   pieces = [1 item]       pieces = [1 item]         pieces = [3 items]
   (650 < 900)             (650 < 900)               (3000 > 900)
        â”‚                     â”‚                         â”‚
        â–¼                     â–¼                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  for piece in pieces:                               â”‚
    â”‚    text = piece.strip()                             â”‚
    â”‚    if not text: continue                            â”‚
    â”‚    output.append(TextChunk(..., chunk_index=N))    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: List[TextChunk]                                        â”‚
â”‚ [                                                               â”‚
â”‚   TextChunk(..., chunk_index=1),  # Trang 5                    â”‚
â”‚   TextChunk(..., chunk_index=2),  # Trang 10, pháº§n 1           â”‚
â”‚   TextChunk(..., chunk_index=3),  # Trang 10, pháº§n 2           â”‚
â”‚   TextChunk(..., chunk_index=4),  # Trang 10, pháº§n 3           â”‚
â”‚ ]                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Points - Nhá»¯ng Äiá»ƒm Quan Trá»ng

| KhÃ¡i Niá»‡m | Ã NghÄ©a |
|-----------|--------|
| **chunk_size=900** | Má»—i chunk tá»‘i Ä‘a 900 kÃ½ tá»± |
| **chunk_overlap=200** | Chunk tiáº¿p theo báº¯t Ä‘áº§u 200 kÃ½ tá»± tá»« cuá»‘i chunk trÆ°á»›c |
| **separators** | Æ¯u tiÃªn chia: paragraph â†’ dÃ²ng â†’ tá»« â†’ kÃ½ tá»± |
| **for chunk in chunks** | VÃ²ng láº·p qua tá»«ng trang/pháº§n tá»« text_extractor |
| **pieces = _splitter.split_text(...)** | Thá»±c hiá»‡n viá»‡c chia |
| **for piece in pieces** | VÃ²ng láº·p qua tá»«ng Ä‘oáº¡n sau khi chia |
| **chunk_index = len(output) + 1** | Sá»‘ thá»© tá»± chunk (1-based) |
| **.strip()** | XÃ³a khoáº£ng tráº¯ng vÃ  newline Ä‘áº§u/cuá»‘i |
| **if not text: continue** | Bá» qua cÃ¡c chunk trá»‘ng |

---

## ğŸ’¡ Táº¡i Sao Cáº§n Chunk?

1. **LLM token limit**: Model AI chá»‰ cÃ³ thá»ƒ xá»­ lÃ½ tá»‘i Ä‘a ~4096 token. VÄƒn báº£n quÃ¡ dÃ i pháº£i chia nhá».
2. **Embedding model input**: SentenceTransformer cÅ©ng cÃ³ giá»›i háº¡n Ä‘á»™ dÃ i.
3. **Similarity search tá»‘t hÆ¡n**: Chunk nhá» â†’ tÃ¬m kiáº¿m chÃ­nh xÃ¡c hÆ¡n (khi user há»i cÃ¢u há»i, sáº½ match Ä‘Æ°á»£c chunk Ä‘Ãºng).

---

## ğŸ¯ TÃ³m Láº¡i

**Chunker lÃ m cÃ´ng viá»‡c sau:**

1. **Nháº­n input**: Má»—i trang tá»« text_extractor (má»™t DocumentChunk)
2. **Chia nhá»**: DÃ¹ng RecursiveCharacterTextSplitter chia theo má»¥c (nháº¥t) â†’ dÃ²ng â†’ tá»« â†’ kÃ½ tá»±
3. **Add vÃ o output**: Má»—i Ä‘oáº¡n trá»Ÿ thÃ nh TextChunk vá»›i:
   - `text`: ná»™i dung
   - `page_number`: sá»‘ trang gá»‘c
   - `chunk_index`: sá»‘ thá»© tá»± global
4. **Return**: List[TextChunk] - táº¥t cáº£ chunks tá»« toÃ n bá»™ document

**Káº¿t quáº£:** Má»™t document 10 trang cÃ³ thá»ƒ trá»Ÿ thÃ nh 50-100 chunks nhá», má»—i chunk ~900 kÃ½ tá»±, sáºµn sÃ ng cho embedding.

---

## ğŸ¬ Flow HoÃ n Chá»‰nh

```
PDF File
    â”‚
    â–¼
[text_extractor.py] â†’ Iterable[DocumentChunk]
    (Má»—i trang = 1 chunk)
    â”‚
    â–¼
[chunker.py] â†’ List[TextChunk]
    (Má»—i chunk trang Ä‘Æ°á»£c chia thÃ nh nhiá»u chunks nhá»)
    â”‚
    â–¼
[embedder.py] â†’ List[EmbeddingResult]
    (Má»—i chunk cÃ³ embedding vector 768 chiá»u)
    â”‚
    â–¼
[pipeline.py â†’ supabase_client.py] â†’ Supabase DB
    (LÆ°u trá»¯)
```

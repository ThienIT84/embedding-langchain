from __future__ import annotations

import logging
import os
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

from langchain_community.retrievers import TavilySearchAPIRetriever
from .retriever import RetrievedChunk, retrieve_similar_chunks_by_user

# Thi·∫øt l·∫≠p logging
logger = logging.getLogger(__name__)

@dataclass
class HybridRetrievalResult:
    """K·∫øt qu·∫£ retrieval t·ª´ nhi·ªÅu ngu·ªìn."""
    sources: List[RetrievedChunk]
    metadata: Dict[str, Any]

class HybridRetriever:
    """
    Hybrid Retriever k·∫øt h·ª£p:
    1. Internal Knowledge Base (Supabase vector search)
    2. External Web Search (Tavily AI)
    """
    
    def __init__(self):
        self.tavily_api_key = os.getenv("TAVILY_API_KEY")
        if not self.tavily_api_key:
            logger.warning("‚ö†Ô∏è TAVILY_API_KEY not found. Web search will be disabled.")
            self.tavily_retriever = None
        else:
            self.tavily_retriever = TavilySearchAPIRetriever(
                k=3,  # Default web results
                api_key=self.tavily_api_key,
                search_depth="advanced"
            )

    def retrieve(
        self, 
        query: str, 
        user_id: str, 
        document_id: Optional[str] = None,  # ‚≠ê NEW: N·∫øu c√≥ = ch·ªâ t√¨m trong file n√†y
        top_k: int = 5,
        include_web: bool = True,
        web_max_results: int = 3,
        internal_max_results: int = 5
    ) -> HybridRetrievalResult:
        """
        QUY TR√åNH HYBRID RETRIEVAL:
        
        1. INTERNAL SEARCH (Supabase):
           - T√¨m ki·∫øm trong database documents c·ªßa user.
           - D√πng Vector Search (pgvector) ƒë·ªÉ t√¨m c√°c chunk t∆∞∆°ng ƒë·ªìng.
           
        2. WEB SEARCH (Tavily):
           - N·∫øu include_web=True -> G·ªçi Tavily API.
           - T√¨m ki·∫øm th√¥ng tin m·ªõi nh·∫•t tr√™n internet.
           
        3. MERGE & RANK:
           - G·ªôp k·∫øt qu·∫£ t·ª´ c·∫£ 2 ngu·ªìn.
           - S·∫Øp x·∫øp l·∫°i theo ƒëi·ªÉm s·ªë (Similarity Score).
           - C·∫Øt l·∫•y top_k k·∫øt qu·∫£ t·ªët nh·∫•t.
        """
        all_chunks: List[RetrievedChunk] = []
        metadata = {
            "internal_results": 0,
            "web_results": 0,
            "total_results": 0
        }

        # --- B∆Ø·ªöC 1: INTERNAL RETRIEVAL (Vector Search) ---
        try:
            if document_id:
                # ‚≠ê Use case: Chat trong context c·ªßa 1 file c·ª• th·ªÉ
                # VD: User ƒëang xem file PDF v√† h·ªèi "B√†i b√°o n√†y n√≥i v·ªÅ g√¨?"
                from .retriever import retrieve_similar_chunks_by_document
                internal_chunks = retrieve_similar_chunks_by_document(
                    query=query,
                    document_id=document_id,
                    top_k=internal_max_results
                )
                logger.info(f"üìÑ Document-specific retrieval: found {len(internal_chunks)} chunks from document {document_id}")
            else:
                # Use case: Global chat - t√¨m trong T·∫§T C·∫¢ documents c·ªßa user
                internal_chunks = retrieve_similar_chunks_by_user(
                    query=query,
                    user_id=user_id,
                    top_k=internal_max_results
                )
                logger.info(f"üìö Internal retrieval: found {len(internal_chunks)} chunks")
                
            all_chunks.extend(internal_chunks)
            metadata["internal_results"] = len(internal_chunks)
        except Exception as e:
            logger.error(f"‚ùå Internal retrieval failed: {e}")

        # --- B∆Ø·ªöC 2: EXTERNAL RETRIEVAL (Tavily Web Search) ---
        if include_web and self.tavily_retriever:
            try:
                # Update k for this request
                self.tavily_retriever.k = web_max_results
                
                # Tavily tr·∫£ v·ªÅ List[Document] c·ªßa LangChain
                web_docs = self.tavily_retriever.invoke(query)
                
                # Convert sang RetrievedChunk format
                web_chunks = []
                for i, doc in enumerate(web_docs):
                    # T√≠nh gi·∫£ l·∫≠p similarity score (th·∫•p h∆°n internal m·ªôt ch√∫t ƒë·ªÉ ∆∞u ti√™n internal)
                    # Ho·∫∑c d√πng rank ƒë·ªÉ suy ra score: 0.8 - (rank * 0.05)
                    sim_score = 0.85 - (i * 0.05)
                    
                    # L·∫•y metadata t·ª´ Tavily doc
                    source_url = doc.metadata.get('source', 'Unknown URL')
                    title = doc.metadata.get('title', 'Web Result')
                    
                    chunk = RetrievedChunk(
                        content=doc.page_content,
                        chunk_index=i,
                        page_number=None,
                        similarity=sim_score,
                        metadata={
                            'source': 'web',  # ƒê√°nh d·∫•u ƒë√¢y l√† web source
                            'url': source_url,
                            'title': title
                        }
                    )
                    
                    web_chunks.append(chunk)

                all_chunks.extend(web_chunks)
                metadata["web_results"] = len(web_chunks)
                logger.info(f"üåê Web retrieval: found {len(web_chunks)} results")
                
            except Exception as e:
                logger.error(f"‚ùå Web retrieval failed: {e}")

        # --- B∆Ø·ªöC 3: RE-RANKING / SORTING (Simple merge based on similarity) ---
        # Internal chunks c√≥ cosine similarity th·ª±c (0-1).
        # Web chunks c√≥ gi·∫£ l·∫≠p similarity (0.85 xu·ªëng).
        # Sort l·∫°i to√†n b·ªô list
        all_chunks.sort(key=lambda x: x.similarity, reverse=True)
        
        # C·∫Øt top_k
        final_chunks = all_chunks[:top_k]
        metadata["total_results"] = len(final_chunks)

        return HybridRetrievalResult(
            sources=final_chunks,
            metadata=metadata
        )

# Singleton instance
hybrid_retriever = HybridRetriever()

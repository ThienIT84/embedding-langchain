# ğŸ”„ Luá»“ng Dá»¯ Liá»‡u: Tá»« text_extractor â†’ chunker â†’ embedder

## â“ CÃ¢u Há»i Cá»§a Báº¡n

> "TÃ´i tháº¥y embedder.py láº¥y TextChunk tá»« chunker.py, nhÆ°ng chunker.py `__init__` chÆ°a set `chunk_index`. Sao á»Ÿ embedder thÃ¬ `TextChunk(text="Ná»™i dung 1", page_number=1, chunk_index=1)` láº¡i Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a Ä‘Ãºng?"

## âœ… Tráº£ Lá»i: **Báº¡n nháº­n xÃ©t ÄÃšNG! NhÆ°ng hiá»ƒu nháº§m luá»“ng dá»¯ liá»‡u.**

---

## ğŸ” Hiá»ƒu Láº¡i: Chunker.py ÄÃƒ SET chunk_index!

### Xem Láº¡i Code chunker.py:

```python
def split_chunks(chunks: Iterable[DocumentChunk]) -> List[TextChunk]:
    """TÃ¡ch láº§n lÆ°á»£t tá»«ng DocumentChunk thÃ nh cÃ¡c TextChunk nhá» hÆ¡n."""
    output: List[TextChunk] = []
    for source_idx, chunk in enumerate(chunks):
        pieces = _splitter.split_text(chunk.text)
        for piece_idx, piece in enumerate(pieces):
            text = piece.strip()
            if not text:
                continue
            output.append(
                TextChunk(
                    text=text,
                    page_number=chunk.page_number,
                    chunk_index=len(output) + 1,  # ğŸ‘ˆ ÄÃƒ SET! DÃ²ng nÃ y ráº¥t quan trá»ng
                )
            )
    return output
```

### ğŸ¯ DÃ²ng Quan Trá»ng:

```python
chunk_index=len(output) + 1,
```

**ÄÃ¢y lÃ  nÆ¡i `chunk_index` Ä‘Æ°á»£c SET!**

---

## ğŸ“Š Luá»“ng Dá»¯ Liá»‡u Chi Tiáº¿t

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ text_extractor.py   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ yield DocumentChunk
           â”‚ (text, page_number)
           â”‚ âŒ CHÆ¯A cÃ³ chunk_index
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ chunker.py          â”‚
â”‚ split_chunks()      â”‚
â”‚                     â”‚
â”‚ Táº¡o TextChunk:      â”‚
â”‚ - text: from piece  â”‚
â”‚ - page_number: tá»«   â”‚
â”‚   chunk gá»‘c         â”‚
â”‚ - chunk_index:      â”‚
â”‚   len(output) + 1   â”‚ âœ… SET Táº I ÄÃ‚Y
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ return List[TextChunk]
           â”‚ (text, page_number, chunk_index)
           â”‚ âœ… ÄÃƒ CÃ“ chunk_index
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ embedder.py         â”‚
â”‚ embed_chunks()      â”‚
â”‚                     â”‚
â”‚ Láº¥y TextChunk:      â”‚
â”‚ - text âœ“            â”‚
â”‚ - page_number âœ“     â”‚
â”‚ - chunk_index âœ“     â”‚
â”‚                     â”‚
â”‚ Táº¡o EmbeddingResult:â”‚
â”‚ - chunk (TextChunk) â”‚
â”‚ - vector (embedding)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ return List[EmbeddingResult]
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pipeline.py         â”‚
â”‚ LÆ°u vÃ o DB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¬ VÃ­ Dá»¥ Chi Tiáº¿t: Tá»«ng BÆ°á»›c

### BÆ¯á»šC 1: text_extractor.py - Táº¡o DocumentChunk

```python
# text_extractor.py: extract_pdf_text()

def extract_pdf_text(file_path: Path) -> Iterable[DocumentChunk]:
    reader = PdfReader(str(file_path))
    for idx, page in enumerate(reader.pages, start=1):
        text = page.extract_text() or ""
        text = text.replace("\x00", "").strip()
        if not text:
            continue
        yield DocumentChunk(text=text, page_number=idx)
        #      â†‘ Chá»‰ cÃ³ 2 thuá»™c tÃ­nh!
        #      text + page_number
        #      CHÆ¯A cÃ³ chunk_index
```

**Output tá»« text_extractor:**

```python
[
    DocumentChunk(text="Trang 1 ná»™i dung...", page_number=1),
    #             â†‘ chá»‰ cÃ³ text vÃ  page_number
    
    DocumentChunk(text="Trang 2 ná»™i dung...", page_number=2),
    DocumentChunk(text="Trang 3 ná»™i dung...", page_number=3),
]
```

---

### BÆ¯á»šC 2: chunker.py - Táº¡o TextChunk (CÃ“ chunk_index)

```python
# chunker.py: split_chunks()

def split_chunks(chunks: Iterable[DocumentChunk]) -> List[TextChunk]:
    output: List[TextChunk] = []
    
    for source_idx, chunk in enumerate(chunks):  # chunk tá»« text_extractor
        pieces = _splitter.split_text(chunk.text)
        
        for piece_idx, piece in enumerate(pieces):
            text = piece.strip()
            
            if not text:
                continue
            
            # âœ… ÄÃ‚Y LÃ€ NÆ I Táº O TextChunk Vá»šI chunk_index!
            output.append(
                TextChunk(
                    text=text,                           # Tá»« pieces
                    page_number=chunk.page_number,       # Tá»« DocumentChunk gá»‘c
                    chunk_index=len(output) + 1,         # âœ… SET Táº I ÄÃ‚Y!
                )
            )
    
    return output
```

**Xá»­ LÃ½ Chi Tiáº¿t:**

```
Input: [DocumentChunk(text="Trang 1...", page_number=1)]

Iteration 1:
  chunk = DocumentChunk(text="Trang 1...", page_number=1)
  pieces = _splitter.split_text("Trang 1...")
         = ["Äoáº¡n 1a", "Äoáº¡n 1b", "Äoáº¡n 1c"]  (3 pháº§n)
  
  Piece 1:
    text = "Äoáº¡n 1a"
    output.append(TextChunk(
        text="Äoáº¡n 1a",
        page_number=1,
        chunk_index=len(output) + 1 = 0 + 1 = 1  âœ…
    ))
    output = [TextChunk1]
  
  Piece 2:
    text = "Äoáº¡n 1b"
    output.append(TextChunk(
        text="Äoáº¡n 1b",
        page_number=1,
        chunk_index=len(output) + 1 = 1 + 1 = 2  âœ…
    ))
    output = [TextChunk1, TextChunk2]
  
  Piece 3:
    text = "Äoáº¡n 1c"
    output.append(TextChunk(
        text="Äoáº¡n 1c",
        page_number=1,
        chunk_index=len(output) + 1 = 2 + 1 = 3  âœ…
    ))
    output = [TextChunk1, TextChunk2, TextChunk3]
```

**Output tá»« chunker:**

```python
[
    TextChunk(text="Äoáº¡n 1a", page_number=1, chunk_index=1),  # âœ… CÃ“ chunk_index
    TextChunk(text="Äoáº¡n 1b", page_number=1, chunk_index=2),
    TextChunk(text="Äoáº¡n 1c", page_number=1, chunk_index=3),
]
```

---

### BÆ¯á»šC 3: embedder.py - Nháº­n TextChunk (ÄÃƒ CÃ“ chunk_index)

```python
# embedder.py: embed_chunks()

def embed_chunks(chunks: Iterable[TextChunk]) -> List[EmbeddingResult]:
    """chunks Ä‘áº¿n tá»« chunker, ÄÃƒ CÃ“ chunk_index"""
    
    chunk_list = list(chunks)
    # chunk_list = [
    #     TextChunk(text="Äoáº¡n 1a", page_number=1, chunk_index=1),
    #     TextChunk(text="Äoáº¡n 1b", page_number=1, chunk_index=2),
    #     TextChunk(text="Äoáº¡n 1c", page_number=1, chunk_index=3),
    # ]
    
    if not chunk_list:
        return []
    
    model = _get_model()
    
    # Láº¥y táº¥t cáº£ text
    texts = [chunk.text for chunk in chunk_list]
    # texts = ["Äoáº¡n 1a", "Äoáº¡n 1b", "Äoáº¡n 1c"]
    
    # Sinh embedding
    embeddings = model.encode(texts, show_progress_bar=True)
    # embeddings = [
    #     [0.1, 0.2, 0.3, ...],  (768 sá»‘)
    #     [0.4, 0.5, 0.6, ...],  (768 sá»‘)
    #     [0.7, 0.8, 0.9, ...],  (768 sá»‘)
    # ]
    
    # GhÃ©p chunks + embeddings
    result = [
        EmbeddingResult(
            chunk=chunk,  # âœ… chunk ÄÃƒ CÃ“ chunk_index
            vector=np.array(vector, dtype=np.float32)
        )
        for chunk, vector in zip(chunk_list, embeddings)
    ]
    
    # result = [
    #     EmbeddingResult(
    #         chunk=TextChunk(..., chunk_index=1),
    #         vector=[0.1, 0.2, ...]
    #     ),
    #     EmbeddingResult(
    #         chunk=TextChunk(..., chunk_index=2),
    #         vector=[0.4, 0.5, ...]
    #     ),
    #     EmbeddingResult(
    #         chunk=TextChunk(..., chunk_index=3),
    #         vector=[0.7, 0.8, ...]
    #     ),
    # ]
    
    return result
```

**Output tá»« embedder:**

```python
[
    EmbeddingResult(
        chunk=TextChunk(text="Äoáº¡n 1a", page_number=1, chunk_index=1),
        vector=np.array([0.1, 0.2, ...])
    ),
    EmbeddingResult(
        chunk=TextChunk(text="Äoáº¡n 1b", page_number=1, chunk_index=2),
        vector=np.array([0.4, 0.5, ...])
    ),
    EmbeddingResult(
        chunk=TextChunk(text="Äoáº¡n 1c", page_number=1, chunk_index=3),
        vector=np.array([0.7, 0.8, ...])
    ),
]
```

---

## ğŸ¯ Báº£ng So SÃ¡nh: Dá»¯ Liá»‡u á» Má»—i Giai Äoáº¡n

| Giai Äoáº¡n | Lá»›p | text | page_number | chunk_index | Tráº¡ng ThÃ¡i |
|-----------|-----|------|-------------|-------------|-----------|
| **text_extractor.py** | `DocumentChunk` | âœ… | âœ… | âŒ | ChÆ°a set |
| **chunker.py (output)** | `TextChunk` | âœ… | âœ… | âœ… | ÄÃ£ set |
| **embedder.py** | `EmbeddingResult.chunk` | âœ… | âœ… | âœ… | CÃ³ sáºµn |

---

## ğŸ’¡ LÃ½ Do Báº¡n Nháº§m Láº«n

### á» File EXTRACTOR_CHUNKER_EMBEDDER_EXPLAINED.md:

TÃ´i viáº¿t vÃ­ dá»¥ cho embedder:

```python
EmbeddingResult(
    chunk=TextChunk(text="Ná»™i dung 1", page_number=1, chunk_index=1),
    vector=...
),
```

**Báº¡n há»i:** "Sao `chunk_index=1` Ä‘Æ°á»£c mÃ  chunker.py `__init__` khÃ´ng set?"

**CÃ¢u Tráº£ Lá»i:** 
- **Chunker ÄÃƒ set!** (dÃ²ng `chunk_index=len(output) + 1`)
- Embedder CHá»ˆ nháº­n TextChunk tá»« chunker
- TextChunk tá»« chunker ÄÃƒ CÃ“ `chunk_index`

### TÃ´i Viáº¿t Bá»‹ Nháº§m HÃ¬nh áº¢nh

á» vÃ­ dá»¥ embedder, tÃ´i nÃªn viáº¿t rÃµ hÆ¡n:

```python
# âŒ SAI: Táº¡o TextChunk trá»±c tiáº¿p (nhÆ° á»Ÿ chunker)
chunk = TextChunk(text="Ná»™i dung 1", page_number=1, chunk_index=1)

# âœ… ÄÃšNG: Nháº­n TextChunk tá»« chunker
chunk = ...  # Tá»« split_chunks() return

# Rá»“i dÃ¹ng nÃ³:
result = EmbeddingResult(chunk=chunk, vector=...)
```

---

## ğŸ”„ Luá»“ng Dá»¯ Liá»‡u Thá»±c Táº¿ (pipeline.py)

```python
# pipeline.py

def process_document(document_id: str) -> None:
    """Quy trÃ¬nh chÃ­nh"""
    
    # BÆ°á»›c 1: Táº£i file PDF
    file_path = download_file(...)
    
    # BÆ°á»›c 2: Extract text (má»—i trang = 1 DocumentChunk)
    # âŒ CHÆ¯A cÃ³ chunk_index
    document_chunks = extract_pdf_text(file_path)
    #  â†“
    # [DocumentChunk(..., page=1), DocumentChunk(..., page=2)]
    
    # BÆ°á»›c 3: Chia chunks (táº¡o TextChunk vá»›i chunk_index)
    # âœ… ÄÃƒ set chunk_index
    text_chunks = split_chunks(document_chunks)
    #  â†“
    # [TextChunk(..., page=1, index=1), TextChunk(..., page=1, index=2), ...]
    
    # BÆ°á»›c 4: Sinh embedding
    # âœ… chunk ÄÃƒ CÃ“ chunk_index
    embeddings = embed_chunks(text_chunks)
    #  â†“
    # [EmbeddingResult(chunk=..., vector=...), ...]
    
    # BÆ°á»›c 5: LÆ°u vÃ o DB
    records = _prepare_records(document_id, embeddings)
    insert_embeddings(records)
```

---

## âœ… Káº¿t Luáº­n

**Chunker ÄÃƒ set `chunk_index`!**

```python
# chunker.py - DÃ²ng quan trá»ng:
output.append(
    TextChunk(
        text=text,
        page_number=chunk.page_number,
        chunk_index=len(output) + 1,  # âœ… SET Táº I ÄÃ‚Y
    )
)
```

**Flow dá»¯ liá»‡u:**
```
text_extractor (chÆ°a index)
    â†“ yield
chunker (táº¡o index)  â† SET chunk_index Táº I ÄÃ‚Y
    â†“ return
embedder (dÃ¹ng sáºµn index)
    â†“
pipeline (lÆ°u index vÃ o DB)
```

**Báº¡n khÃ´ng nháº§m láº«n logic, chá»‰ lÃ  flow dá»¯ liá»‡u qua cÃ¡c file lÃ m báº¡n confused!** ğŸ‰

BÃ¢y giá» hiá»ƒu rÃµ hÆ¡n chÆ°a?
